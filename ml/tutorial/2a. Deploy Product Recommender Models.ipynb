{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3cd8e3",
   "metadata": {},
   "source": [
    "# Deploying a Model using Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b3b31",
   "metadata": {},
   "source": [
    "The steps to deploy any model are:\n",
    "\n",
    "1. Register the model\n",
    "2. Prepare an entry script\n",
    "3. Prepare an inference configuration and a deployment configuration\n",
    "4. Deploy the model locally to ensure everything works\n",
    "5. Choose a compute target.\n",
    "6. Re-deploy the model to the cloud\n",
    "7. Test the resulting web service.\n",
    "\n",
    "\n",
    "[You can learn more by reading these official docs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f6f481",
   "metadata": {},
   "source": [
    "## 0. Connect to AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f048f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: SignalBoxMLDev\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Dataset, Model, Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "subscription_id = 'ad2a181b-b804-4179-904a-012445b7d1f5'\n",
    "resource_group = 'analyticsf7fa8b0c'\n",
    "workspace_name = 'SignalBoxMLDev'\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "print('Connected to workspace:', ws.name)\n",
    "\n",
    "model_version = 'product-1'\n",
    "tags = {\n",
    "    'source': 'tutorial',\n",
    "    'production': False,\n",
    "    'version': model_version\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84a478",
   "metadata": {},
   "source": [
    "## 1. Register a model\n",
    "\n",
    "A typical situation for a deployed machine learning service is that you need the following components:\n",
    "\n",
    "* resources representing the specific model that you want deployed (for example: a pytorch model file)\n",
    "* code that you will be running in th service, that executes the model on a given input\n",
    "\n",
    "Azure Machine Learning allows you to separate the deployment into two separate components, so that you can keep the same code, but merely update the model. We define the mechanism by which you upload a model separately from your code as \"registering the model\".\n",
    "\n",
    "You can register a model by providing the local path of the model. You can provide the path of either a folder or a single file on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f490eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple file as the specific 'model' we're going to use.\n",
    "import pickle\n",
    "\n",
    "model_parameters = {'name': 'product-recommender-tutorial-model',\n",
    "        'parameters': {\n",
    "            'weights': [0.6, 0.3, 0.1]\n",
    "        }\n",
    "    }\n",
    "model_filename = 'product_recommender_tutorial.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as handle:\n",
    "    pickle.dump(model_parameters, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a11c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model product-recommender-tutorial-model\n"
     ]
    }
   ],
   "source": [
    "# register the model\n",
    "model_properties = {\n",
    "    'source': 'product-recommender-tutorial',\n",
    "    'version': model_version\n",
    "}\n",
    "model = Model.register(ws, \n",
    "                       model_name=model_parameters['name'], \n",
    "                       model_path=model_filename, \n",
    "                       tags=tags\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80acd40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(workspace=Workspace.create(name='SignalBoxMLDev', subscription_id='ad2a181b-b804-4179-904a-012445b7d1f5', resource_group='analyticsf7fa8b0c'), name=product-recommender-tutorial-model, id=product-recommender-tutorial-model:1, version=1, tags={'source': 'tutorial', 'production': 'False', 'version': 'product-1'}, properties={})\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ed24e",
   "metadata": {},
   "source": [
    "## 2. Prepare an entry script\n",
    "\n",
    "The entry script receives data submitted to a deployed web service and passes it to the model. It then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns.\n",
    "\n",
    "> You can use the environment variable `AZUREML_MODEL_DIR` to locate your model that you registered earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45ced3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting product_recommender_source_dir/entry.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile product_recommender_source_dir/entry.py \n",
    "\n",
    "\n",
    "# this is an actual entry script\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "\n",
    "possible_outcomes = [\n",
    "    {\n",
    "        'productId': 5,\n",
    "    },\n",
    "    {\n",
    "        'productId': 6,\n",
    "    },\n",
    "    {\n",
    "        'productId': 7,\n",
    "    },\n",
    "]\n",
    "def init():\n",
    "    global model_parameters\n",
    "    with open(os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'product_recommender_tutorial.pkl'), 'rb') as handle:\n",
    "        model_parameters = pickle.load(handle)['parameters']\n",
    "\n",
    "# request should have: payload: {},  version: str\n",
    "def run(request):\n",
    "    print(request)\n",
    "    body = json.loads(request)\n",
    "    version = body['version']\n",
    "    ## check we can handle the version\n",
    "    print(f'Version: {version}')\n",
    "\n",
    "    # Run inference\n",
    "    recommendation = recommend(body['payload'])\n",
    "    print('recommendation:', recommendation)\n",
    "   \n",
    "    return recommendation\n",
    "\n",
    "# assuming this is a paremeter-set recommender\n",
    "# payload is json with arguments, parameters (both objects)\n",
    "def recommend(r):\n",
    "    # sort the offers by ID\n",
    "    arguments = r['arguments']\n",
    "    commonUserId = r['commonUserId']\n",
    "    print(arguments)\n",
    "    # you can load parameters from the model if you need ot.\n",
    "    print('model params:', model_parameters['weights'])\n",
    "    # random.choices() returns a list of k length\n",
    "    return random.choices(possible_outcomes, model_parameters['weights'], k=1)[0] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddcd07",
   "metadata": {},
   "source": [
    "## 3. Prepare an inference configuration and a deployment configuration\n",
    "\n",
    "### Inference\n",
    "\n",
    "An inference configuration describes the Docker container and files to use when initializing your web service. All of the files within your source directory, including subdirectories, will be zipped up and uploaded to the cloud when you deploy your web service.\n",
    "\n",
    "### Deployment\n",
    "\n",
    "A deployment configuration specifies the amount of memory and cores to reserve for your webservice will require in order to run, as well as configuration details of the underlying webservice. For example, a deployment configuration lets you specify that your service needs 2 gigabytes of memory, 2 CPU cores, 1 GPU core, and that you want to enable autoscaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f2fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.from_pip_requirements(name='tutorial_environment', file_path=\"./model_requirements.txt\")\n",
    "inference_config = InferenceConfig(environment=env, source_directory='product_recommender_source_dir', entry_script='./entry.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addc0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a local webservice\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5619ade",
   "metadata": {},
   "source": [
    "## 4. Deploy the model locally to ensure everything works\n",
    "\n",
    "This part needs docker installed and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b160b8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model product-recommender-tutorial-model:1 to /var/folders/r9/zky7_kgn5955p246_2p84brh0000gn/T/azureml_yulbnvnz/product-recommender-tutorial-model/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry mlresgistryfe091fe9.azurecr.io\n",
      "Logging into Docker registry mlresgistryfe091fe9.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM mlresgistryfe091fe9.azurecr.io/azureml/azureml_984ae42c92ab7e15d7808a45a9ac459f\n",
      " ---> 2f5da5597264\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 0e7633d8ee18\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImFkMmExODFiLWI4MDQtNDE3OS05MDRhLTAxMjQ0NWI3ZDFmNSIsInJlc291cmNlR3JvdXBOYW1lIjoiYW5hbHl0aWNzZjdmYThiMGMiLCJhY2NvdW50TmFtZSI6InNpZ25hbGJveG1sZGV2Iiwid29ya3NwYWNlSWQiOiIyNTJmNTM5Ni03NmYwLTRjZDYtOGE3OS0wYjQ5ZGI3NmM1MGIifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 9b1fa4c30901\n",
      " ---> 61b97550fcd1\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpkeux4vlt.py' /var/azureml-app/main.py\n",
      " ---> Running in 3f4c972232b9\n",
      " ---> e6f5b75b22f1\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in d6da9cf79c78\n",
      " ---> 454fe655b3d8\n",
      "Successfully built 454fe655b3d8\n",
      "Successfully tagged tutorial-service-local:latest\n",
      "Container (name:elated_hodgkin, id:7baf3ea895b6635ee22d43fdf63ef75fd037680fae49e7f993c660744a5a57ae) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:cae53e9b6cb6857b1f7505cc5e37bcbb5934242b345ef1dd3eab29748a4617aa successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n",
      "2021-07-05T05:26:09,100127200+00:00 - rsyslog/run \n",
      "2021-07-05T05:26:09,100127200+00:00 - gunicorn/run \n",
      "2021-07-05T05:26:09,102650600+00:00 - iot-server/run \n",
      "2021-07-05T05:26:09,102584400+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-07-05T05:26:09,178639300+00:00 - iot-server/finish 1 0\n",
      "2021-07-05T05:26:09,180063200+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 46\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-07-05 05:26:09,452 | root | INFO | Starting up app insights client\n",
      "2021-07-05 05:26:09,452 | root | INFO | Starting up request id generator\n",
      "2021-07-05 05:26:09,452 | root | INFO | Starting up app insight hooks\n",
      "2021-07-05 05:26:09,452 | root | INFO | Invoking user's init function\n",
      "2021-07-05 05:26:09,452 | root | INFO | Users's init has completed successfully\n",
      "2021-07-05 05:26:09,454 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-07-05 05:26:09,454 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-07-05 05:26:09,454 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"tutorial-service-local\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe3e65",
   "metadata": {},
   "source": [
    "Call the local docker container to check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f59636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"version\": \"parameter-set-1\", # check this version mathes\n",
    "    \"payload\": {\n",
    "        \"commonUserId\": \"1234\",\n",
    "        \"arguments\": {\n",
    "            \"one\": 1,\n",
    "            \"two\": \"foobar\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "253d7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:6789/score\n",
      "model responded with:\n",
      "{'productId': 6}\n"
     ]
    }
   ],
   "source": [
    "# check the model works\n",
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "print(uri)\n",
    "# requests.get('http://localhost:6789')\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data_stringified = json.dumps(data)\n",
    "response = requests.post(uri, data=data_stringified, headers=headers)\n",
    "print('model responded with:')\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8666922",
   "metadata": {},
   "source": [
    "## 5. Choose a compute target.\n",
    "\n",
    "[Learn more about choosing a target](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python#choose-a-compute-target)\n",
    "\n",
    "Options are:\n",
    "* Local web service: for testing and debugging\n",
    "* Azure Kubernetes Services: High scale production (probably don't do this without bigger discussion)\n",
    "* Azure Container Instances: Low scale, less than 48GB RAM\n",
    "* Azure Machine Learning compute cluster: best for batch inferencing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9861d",
   "metadata": {},
   "source": [
    "## 6. Re-deploy the model to the cloud\n",
    "\n",
    "Deploy to an Azure Container Instanec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d28459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "aci_deployment_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, \n",
    "                                                           memory_gb = 1, \n",
    "                                                           tags=tags, \n",
    "                                                           auth_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "724cd192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service product-recommender-tutorial-aci with the same name already exists, please use a different service name or delete the existing service.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service product-recommender-tutorial-aci with the same name already exists, please use a different service name or delete the existing service.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-baf61d17f038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                        aci_deployment_config)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signalboxml/lib/python3.7/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_env_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m             return Model._deploy_with_environment(workspace, name, models, inference_config, deployment_config,\n\u001b[0;32m-> 1670\u001b[0;31m                                                   deployment_target, overwrite, show_output)\n\u001b[0m\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;31m# ContainerImage-based webservice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signalboxml/lib/python3.7/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_deploy_with_environment\u001b[0;34m(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[1;32m   1876\u001b[0m         return Model._deploy_with_environment_image_request(workspace, name, environment_image_request,\n\u001b[1;32m   1877\u001b[0m                                                             \u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m                                                             show_output)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signalboxml/lib/python3.7/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_deploy_with_environment_image_request\u001b[0;34m(workspace, name, environment_image_request, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m         return Webservice._deploy_webservice(workspace, name, webservice_payload, overwrite, webservice_class,\n\u001b[0;32m-> 1927\u001b[0;31m                                              show_output)\n\u001b[0m\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sas_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signalboxml/lib/python3.7/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_deploy_webservice\u001b[0;34m(workspace, name, webservice_payload, overwrite, webservice_class, show_output)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \"\"\"\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# TODO Remove check_for_existing_webservice() later, this check has already included in common validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_for_existing_webservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         Webservice._check_for_webservice(workspace, name, Webservice._get_deploy_compute_type(webservice_payload),\n\u001b[1;32m    829\u001b[0m                                          webservice_payload, SERVICE_REQUEST_OPERATION_CREATE)\n",
      "\u001b[0;32m~/miniconda3/envs/signalboxml/lib/python3.7/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mcheck_for_existing_webservice\u001b[0;34m(workspace, name, overwrite, request_func, check_func)\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_validate_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_validate_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/signalboxml/lib/python3.7/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_run_validate_framework\u001b[0;34m(request_func, check_func)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service product-recommender-tutorial-aci with the same name already exists, please use a different service name or delete the existing service.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service product-recommender-tutorial-aci with the same name already exists, please use a different service name or delete the existing service.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# this cell creates a new ACI deployed into Azure.\n",
    "service = Model.deploy(ws, \n",
    "                       \"product-recommender-tutorial-aci\", \n",
    "                       [model], \n",
    "                       inference_config, \n",
    "                       aci_deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b37e1b",
   "metadata": {},
   "source": [
    "## 7. Test the resulting web service.\n",
    "\n",
    "When you deploy remotely, you may have key authentication enabled. The example below shows how to get your service key with Python in order to make an inference request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc080f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring uri:  http://4c57df6a-6624-4fb4-91ba-c02299f59ed5.westus2.azurecontainer.io/score\n",
      "key: K64jyJGFpKxSSHEkxHwFAXigwd2nCBY7\n",
      "the model responded:\n",
      "{\"productId\": 5}\n",
      "{'productId': 5}\n",
      "time taken: 0.369844\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice\n",
    "\n",
    "service = Webservice(workspace=ws, name='product-recommender-tutorial-aci')\n",
    "scoring_uri = service.scoring_uri\n",
    "print('scoring uri: ', scoring_uri)\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "primary_key, _ = service.get_keys()\n",
    "print('key:', primary_key)\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "headers['Authorization'] = f'Bearer {primary_key}'\n",
    "\n",
    "data_stringified = json.dumps(data)\n",
    "response = requests.post(scoring_uri, data=data_stringified, headers=headers)\n",
    "print('the model responded:')\n",
    "print(response.text)\n",
    "print(response.json())\n",
    "print('time taken:', response.elapsed.total_seconds())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6f969",
   "metadata": {},
   "source": [
    "You can get the logs from the remote ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650ee75e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-05T01:33:31,477563800+00:00 - rsyslog/run \n",
      "2021-07-05T01:33:31,482254700+00:00 - gunicorn/run \n",
      "2021-07-05T01:33:31,489107300+00:00 - iot-server/run \n",
      "2021-07-05T01:33:31,527425200+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_abe832532d68e7634ad48db5ac241baf/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (62)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 84\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-07-05T01:33:32,915627900+00:00 - iot-server/finish 1 0\n",
      "2021-07-05T01:33:32,927556800+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-07-05 01:33:33,673 | root | INFO | Starting up app insights client\n",
      "2021-07-05 01:33:33,674 | root | INFO | Starting up request id generator\n",
      "2021-07-05 01:33:33,674 | root | INFO | Starting up app insight hooks\n",
      "2021-07-05 01:33:33,675 | root | INFO | Invoking user's init function\n",
      "2021-07-05 01:33:33,675 | root | INFO | Users's init has completed successfully\n",
      "2021-07-05 01:33:33,678 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-07-05 01:33:33,678 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-07-05 01:33:33,679 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-07-05 01:33:44,158 | root | INFO | Swagger file not present\n",
      "2021-07-05 01:33:44,159 | root | INFO | 404\n",
      "127.0.0.1 - - [05/Jul/2021:01:33:44 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:33:50,256 | root | INFO | Swagger file not present\n",
      "2021-07-05 01:33:50,256 | root | INFO | 404\n",
      "127.0.0.1 - - [05/Jul/2021:01:33:50 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:33:58,987 | root | INFO | Swagger file not present\n",
      "2021-07-05 01:33:58,988 | root | INFO | 404\n",
      "127.0.0.1 - - [05/Jul/2021:01:33:58 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:33:59,710 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:33:59,711 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\": \"parameter-set-1\", \"payload\": {\"commonUserId\": \"1234\", \"touchpointValues\": {\"one\": 1, \"two\": \"foobar\"}}}\n",
      "Version: parameter-set-1\n",
      "{'one': 1, 'two': 'foobar'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:33:59,714 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:33:59 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"python-requests/2.25.1\"\n",
      "2021-07-05 01:44:52,585 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:44:52,586 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 6}\n",
      "2021-07-05 01:44:52,589 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:44:52 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:45:04,831 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:45:04,832 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:45:04,834 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:45:04 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:45:06,450 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:45:06,450 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:45:06,451 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:45:06 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:45:07,687 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:45:07,688 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:45:07,689 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:45:07 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:45:08,840 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:45:08,841 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:45:08,842 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:45:08 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:45:10,428 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:45:10,428 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 7}\n",
      "2021-07-05 01:45:10,430 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:45:10 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:48:18,665 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:48:18,665 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"testing\",\"payload\":{\"commonUserId\":\"1234\",\"touchpointValues\":{\"one\":1,\"two\":\"two\"}}}\n",
      "Version: testing\n",
      "{'one': 1, 'two': 'two'}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:48:18,667 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:48:18 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:51:08,727 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:51:08,727 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"default\",\"payload\":{\"commonUserId\":\"9f73f869065d0ce93de65e8c5265d5cc\",\"version\":null,\"touchpoint\":\"first_product_recommender\",\"touchpointValues\":null}}\n",
      "Version: default\n",
      "None\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:51:08,729 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:51:08 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 01:51:12,437 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 01:51:12,437 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"default\",\"payload\":{\"commonUserId\":\"9f73f869065d0ce93de65e8c5265d5cc\",\"version\":null,\"touchpoint\":\"first_product_recommender\",\"touchpointValues\":null}}\n",
      "Version: default\n",
      "None\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 01:51:12,438 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:01:51:12 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "2021-07-05 03:38:32,196 | root | INFO | Validation Request Content-Type\n",
      "2021-07-05 03:38:32,198 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
      "{\"version\":\"default\",\"payload\":{\"commonUserId\":\"c7db69f32aee307101231334a53d464b\",\"version\":null,\"touchpoint\":\"first_product_recommender\",\"touchpointValues\":{\"test\":\"property\",\"\":\"\"}}}\n",
      "Version: default\n",
      "{'test': 'property', '': ''}\n",
      "model params:\n",
      "[0.6, 0.3, 0.1]\n",
      "recommendation:\n",
      "{'productId': 5}\n",
      "2021-07-05 03:38:32,207 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Jul/2021:03:38:32 +0000] \"POST /score HTTP/1.0\" 200 16 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24171621",
   "metadata": {},
   "source": [
    "## Required information in Four2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29d4f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring url: http://9a084848-7f0b-4a8e-85f1-84719493df60.westus2.azurecontainer.io/score\n",
      "key cWAz6IhpSMeNesNnNCsQhglQlG6NdGn5\n"
     ]
    }
   ],
   "source": [
    "print('scoring url:', scoring_uri)\n",
    "print('key', primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ff3d3",
   "metadata": {},
   "source": [
    "## WELL DONE!\n",
    "\n",
    "You deployed your first model!\n",
    "\n",
    "The next part is making it intelligent.\n",
    "\n",
    "But first, clean up the resources you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c7d6548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n"
     ]
    }
   ],
   "source": [
    "# delete the ACI service you created\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc80d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all the models we created\n",
    "models = Model.list(ws, name=model_parameters['name'])\n",
    "for m in models:\n",
    "    print('deleting', model.name, 'version:' , model.version)\n",
    "    m.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9354ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
